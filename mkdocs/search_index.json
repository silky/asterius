{
    "docs": [
        {
            "location": "/",
            "text": "asterius\n is a Haskell to WebAssembly compiler. The project is in alpha stage and in active development.\n\n\nSponsors\n\n\nAsterius is maintained by \nTweag I/O\n.\n\n\nHave questions? Need help? Tweet at \n@tweagio\n.",
            "title": "Home"
        },
        {
            "location": "/#sponsors",
            "text": "Asterius is maintained by  Tweag I/O .  Have questions? Need help? Tweet at  @tweagio .",
            "title": "Sponsors"
        },
        {
            "location": "/building/",
            "text": "Building guide\n\n\nasterius\n is tested on Linux x64 and Windows x64. macOS x64 may also work. A Docker image is provided.\n\n\ntl;dr: See \n.circleci/config.yml\n for CircleCI config, \nappveyor.yml\n for AppVeyor config.\n\n\nUsing a pre-built Docker image\n\n\nWe build and test Docker images on CircleCI. They are pushed to \nterrorjack/asterius\n, the tags are git revisions. \nterrorjack/asterius:latest\n correspond to latest revision on \nmaster\n.\n\n\nPut input program in a directory (e.g. \n~/mirror\n), then map the directory to a Docker volume:\n\n\nterrorjack@ubuntu:~$ docker run -it -v ~/mirror:/mirror terrorjack/asterius\nroot@76bcb511663d:~# cd /mirror\nroot@76bcb511663d:/mirror# ahc-link --help\n...\n\n\n\n\nBuilding custom \nghc\n\n\nasterius\n requires a custom \nghc\n which:\n\n\n\n\nUses \nghc-head\n instead of a release version. It forces us to keep an eye on upstream changes. The \nmaster\n branch of \nghc\n may introduce breaking commits, so for safety you should choose the specific \nghc\n version as indicated in the \nstack.yaml\n file.\n\n\nDisables \nTABLES_NEXT_TO_CODE\n. It's hard to attach executable code to an info table on the WebAssembly platform.\n\n\nUses \ninteger-simple\n instead of \ninteger-gmp\n. Porting \ninteger-gmp\n to WebAssembly requires extra work and is not currently scheduled.\n\n\n\n\nThe building guide of \nghc\n can be found \nhere\n. Add the following lines to \nmk/build.mk\n:\n\n\nGhcEnableTablesNextToCode = NO\nINTEGER_LIBRARY           = integer-simple\n\n\n\n\nIn addition to your own build configs.\n\n\nOn Linux/Windows, a prebuilt \nghc\n tarball is provided. It's already included in \nstack.yaml\n.\n\n\nExtra dependencies\n\n\nBesides the custom \nghc\n, these dependencies are also required:\n\n\n\n\ncmake\n/\nmake\n/\ng++\n: For building in-tree \nbinaryen\n\n\nautoconf\n: For booting \nghc-prim\n/\nbase\n\n\nnodejs\n: For running tests. Ensure the latest version is used, since we rely on some recent V8 experimental features (e.g. BigInt support)\n\n\nstack\n: Someday \ncabal\n may also work, no specific obstacles anyway.\n\n\n\n\nBuilding \nasterius\n\n\nstack build asterius\n. That's it. Set \nMAKEFLAGS=-j8\n to pass flags to \nmake\n for parallel building of \nbinaryen\n.\n\n\nAfter the dust settles, run \nstack exec ahc-boot\n to perform booting. Set the \nASTERIUS_DEBUG\n environment variable to make \nahc-boot\n pretty-print IRs to text files which are useful when debugging compiled code of standard libraries. Be aware that this flag slows down the booting process significantly!",
            "title": "Building guide"
        },
        {
            "location": "/building/#building-guide",
            "text": "asterius  is tested on Linux x64 and Windows x64. macOS x64 may also work. A Docker image is provided.  tl;dr: See  .circleci/config.yml  for CircleCI config,  appveyor.yml  for AppVeyor config.",
            "title": "Building guide"
        },
        {
            "location": "/building/#using-a-pre-built-docker-image",
            "text": "We build and test Docker images on CircleCI. They are pushed to  terrorjack/asterius , the tags are git revisions.  terrorjack/asterius:latest  correspond to latest revision on  master .  Put input program in a directory (e.g.  ~/mirror ), then map the directory to a Docker volume:  terrorjack@ubuntu:~$ docker run -it -v ~/mirror:/mirror terrorjack/asterius\nroot@76bcb511663d:~# cd /mirror\nroot@76bcb511663d:/mirror# ahc-link --help\n...",
            "title": "Using a pre-built Docker image"
        },
        {
            "location": "/building/#building-custom-ghc",
            "text": "asterius  requires a custom  ghc  which:   Uses  ghc-head  instead of a release version. It forces us to keep an eye on upstream changes. The  master  branch of  ghc  may introduce breaking commits, so for safety you should choose the specific  ghc  version as indicated in the  stack.yaml  file.  Disables  TABLES_NEXT_TO_CODE . It's hard to attach executable code to an info table on the WebAssembly platform.  Uses  integer-simple  instead of  integer-gmp . Porting  integer-gmp  to WebAssembly requires extra work and is not currently scheduled.   The building guide of  ghc  can be found  here . Add the following lines to  mk/build.mk :  GhcEnableTablesNextToCode = NO\nINTEGER_LIBRARY           = integer-simple  In addition to your own build configs.  On Linux/Windows, a prebuilt  ghc  tarball is provided. It's already included in  stack.yaml .",
            "title": "Building custom ghc"
        },
        {
            "location": "/building/#extra-dependencies",
            "text": "Besides the custom  ghc , these dependencies are also required:   cmake / make / g++ : For building in-tree  binaryen  autoconf : For booting  ghc-prim / base  nodejs : For running tests. Ensure the latest version is used, since we rely on some recent V8 experimental features (e.g. BigInt support)  stack : Someday  cabal  may also work, no specific obstacles anyway.",
            "title": "Extra dependencies"
        },
        {
            "location": "/building/#building-asterius",
            "text": "stack build asterius . That's it. Set  MAKEFLAGS=-j8  to pass flags to  make  for parallel building of  binaryen .  After the dust settles, run  stack exec ahc-boot  to perform booting. Set the  ASTERIUS_DEBUG  environment variable to make  ahc-boot  pretty-print IRs to text files which are useful when debugging compiled code of standard libraries. Be aware that this flag slows down the booting process significantly!",
            "title": "Building asterius"
        },
        {
            "location": "/checklist/",
            "text": "Checklist\n\n\nThis page maintains a list of upcoming tasks for the project, each task with a brief explanation, estimation of difficulty/time and connections with other tasks. Ideally this should be called \nRoadmap\n instead of \nChecklist\n, but placing accurate milestones has proven to be hard.\n\n\nTowards a TodoMVC example\n\n\nThe tasks listed in this section are all necessary ones to achieve a more \"real-world\" browser example like TodoMVC. They are currently being worked on.\n\n\nImplement \nforeign export javascript\n\n\nWe already can call JavaScript from Haskell via \nforeign import javascript\n, for JavaScript to call into Haskell, we need to implement \nforeign export javascript\n. The exported Haskell functions will be available as WebAssembly exported functions, callable in JavaScript land.\n\n\nRequirements:\n\n\n\n\nImplement \nStablePtr\n, so that Haskell closures can be safely passed between Haskell/JavaScript boundary without being garbage collected. (done, see \nstableptr\n unit test)\n\n\nImplement \nRtsAPI\n, so that JavaScript code can create Haskell closures, trigger evaluation and inspect results. (done, see \nrtsapi\n unit test)\n\n\nAdd \nStablePtr\n to JSFFI basic types. (done, see \njsffi\n unit test)\n\n\nImplement \nforeign export javascript\n syntax, add necessary logic in \nJSFFI\n/\nResolve\n (in progress)\n\n\n\n\nRough ETA: before Aug 20th.\n\n\nImprove Haskell/JavaScript marshalling\n\n\nMost JavaScript types will appear as opaque \nJSRef\n in Haskell land, but for some types that appear very often (e.g. strings and arrays), we wish they can be marshalled from/to their Haskell equivalents (e.g. lists) smoothly. Without this, even implementing a \nputStr\n will be troublesome because we must either send individual \nChar\ns to a TTY-device in JavaScript, or manually squeeze the string into a buffer in Haskell heap first.\n\n\nRequirements:\n\n\n\n\nRecognize \nString\n/\n[]\n as special JSFFI basic types, add marshalling logic from/to JavaScript strings/arrays. (in progress)\n\n\n\n\nWhen we support \naeson\n in the future, it may even be possible to marshal between \nValue\ns and JavaScript objects directly.\n\n\nSupport \nbytestring\n\n\nbytestring\n is a critical component in the Haskell ecosystem, we must support it regardless of what filthy hacks are deployed. At least non-\nInternal\n modules need to be supported.\n\n\nRequirements:\n\n\n\n\nAdd \nbytestring\n to boot libs.\n\n\nImplement \nWeak#\n, since \nByteString\n needs finalizers\n\n\nImplement WebAssembly shims in \nBuiltins\n for required C functions.\n\n\n\n\nImprove \n.wasm\n/\n.js\n generation\n\n\nCurrently, given a home module, \nahc-link\n outputs a \n.wasm\n and a \n.js\n wrapper which runs in Node.js. We will need the whole thing to run in browser though.\n\n\nRequirements:\n\n\n\n\nAdd logic in \nahc-link\n to generate browser-friendly code\n\n\nMake the test suite run via a headless browser, and properly retrieve results from the browser back to Haskell\n\n\n\n\nNext important tasks\n\n\nThe following tasks are somewhat less important, but still necessary for end-user experience. They will be processed once the previous goal is accomplished.\n\n\nUtilize GHC renamer/typechecker in JSFFI\n\n\nCurrently, the JSFFI thing works with parsed AST because it's less likely to mess up after rewriting. As a consequence:\n\n\n\n\nJSRef\n only works as a magic identifier. It's not in any actual Haskell module\n\n\nNo \nnewtypes\n for JSFFI basic types, since we recognize types by \nRdrName\n only\n\n\n\n\nWe need to move JSFFI processing to the phase of renamer or typechecker.\n\n\nSupport JavaScript promises in JSFFI\n\n\nThe \nforeign import javascript\n syntax currently assumes the JavaScript computation is synchronous. We need to support asynchronous JavaScript computation, by adding a \nforeign import javascript safe\n construct, and assume the JavaScript computation returns a \nPromise\n. Upon calling such a function, the scheduler saves thread state and gracefully halts the whole runtime. The runtime will be re-activated once the \nPromise\n is fulfilled.\n\n\nAdd growable heap/garbage collection to storage manager\n\n\nCurrently, the heap size is fixed and can be specified by \nahc-link --heap-size\n. By defaulting a heap size of 1GB, we pretend memory is infinite and focus work on other issues, but this can come back to bite us at any time.\n\n\nThere are two steps in this tasks:\n\n\n\n\nImplement growable heap. When GC is entered, we allocate fresh blocks and move the nursery/object pool to point to new blocks.\n\n\nImplement garbage collection. Porting all GC routines is a huge amount of work and error-prone, so we implement a non-generational one in JavaScript.\n\n\n\n\nSolve reference leaking in JSFFI\n\n\nJSRef\n is implemented much like \nStablePtr\n: a mapping from handles to objects. Whenever a \nJSRef\n enters Haskell land, the underlying object is pointed to by a mapping, but currently there's no mechanism to free a \nJSRef\n.\n\n\nSome possible fixes:\n\n\n\n\nProvide \nfreeJSRef\n in Haskell land, works for any individual \nJSRef\n\n\nProvide \nnukeJSRefs\n, can be called periodically to wipe all \nJSRef\ns\n\n\nProvide a region-based API, all \nJSRef\ns are tied to a region. Regions themselves can be allocated and recycled. Optionally there can be a global region.\n\n\n\n\nImprove \nCabal\n support\n\n\nCurrently, \nCabal\n still thinks \nahc\n is yet another \nghc\n and feeds it with \nghc\n command line arguments. We should teach it to regard \nahc\n as a new Haskell compiler, and what to do for typical commands (\nconfigure\n/\nbuild\n/\ninstall\n, etc).\n\n\nAfter \nCabal\n support is improved, we can:\n\n\n\n\nGet away with current \"boot libs\" mechanism, instead rely on regular GHC package databases\n\n\nGive users ability to build/use packages outside boot libs\n\n\nGo on with improving \ncabal-install\n, some day a plain \ncabal build --asterius\n may work\n\n\n\n\nImprove test suite\n\n\nThe current test suites have poor coverage of Haskell features.\n\n\nArchived tasks\n\n\nThe following tasks have lower priority, either due to low impact to end-user experience or significant time involved. They are archived here and may be revisited at a later date, and we're still happy to discuss or review a pull request.\n\n\nImplement Template Haskell/GHCi\n\n\nThere are two possible ways to implement Template Haskell/GHCi:\n\n\n\n\nLink with the native code produced when booting. For simple \nQ\n computations that doesn't involve \nrunIO\n this should work fine, but it won't work when one calls a WebAssembly computation in \nQ\n.\n\n\nImplement the remote interpreter for WebAssembly, much like ghcjs. When Template Haskell/GHCi is involved, we fire up a Node.js/Headless Chrome process and do all the message passing. This is the ideal solution but takes a huge amount of work.\n\n\n\n\nImprove WebAssembly EDSL\n\n\nWe already have a monadic EDSL for constructing WebAssembly code. There are still minor flaws with current EDSL:\n\n\n\n\nNo notion of \nstruct\ns. We manually load/store via a base pointer and an offset.\n\n\nNot type-safe. It's possible to mix-up \nI32\n/\nI64\n stuff and it's not always possible for \nbinaryen\n validator to catch the problem (especially when load/store is involved)\n\n\nGlobal/static variables need a lot of boilerplate\n\n\n\n\nSwitch away from \nbinaryen\n\n\nbinaryen\n is a fantastic library for WebAssembly code generation and has powered \nasterius\n since the beginning. However, there are reasons to switch away and implement our own WebAssembly code generation library:\n\n\n\n\nThe relooper has been a constant source of trouble. We already implement our own relooper now.\n\n\nThere's no support for linking and symbol resolution, so we have to keep two sets of types for WebAssembly: one is our own for pre-linking modules, one is the final linked data to feed to \nbinaryen\n, but they overlap a lot.\n\n\nbinaryen\n is conservative in features. We'd like to try experimental WebAssembly features (exception handling, multi-return, anyref, etc) in V8.\n\n\n\n\nIntegrate LLVM/Clang or Emscripten\n\n\nIt's a shame we can't compile simple \ncbits\n in Haskell packages and have to hand-write WebAssembly code instead.\n\n\nImplement \"Try asterius\" website\n\n\nTo increase momentum for this project, it'd be nice to have a \"try asterius\" website, where people can send snippets of modules and download compiled code to run in their browsers.\n\n\nAdd macOS support\n\n\nCurrently we don't build GHC bindists for macOS and test it on CircleCI. For the sake of macOS Haskellers this should be implemented.\n\n\nAdd Nix/Bazel support\n\n\nIt'd be nice to support building the project via Nix/Bazel.\n\n\nSupport \ninteger-gmp\n\n\nWe currently use \ninteger-simple\n, but not all packages implement the flags to switch away from \ninteger-gmp\n.\n\n\nIt's worth mentioning that V8 already has experimental support for the BigInt proposal, so \nInteger\ns should ideally be powered by \nbigint\ns under the hood.\n\n\nSupport tables-next-to-code\n\n\nOf course, we know the WebAssembly standard separates data and code, so something like tables-next-to-code won't work; but come to think of it, at link time we already know the absolute addresses of \"code\", so we can cheat a little bit here..\n\n\nIf we support both \ninteger-gmp\n and tables-next-to-code, we can stop requiring users to set up a custom GHC first, and can distribute \nasterius\n as a vanilla package.",
            "title": "Checklist"
        },
        {
            "location": "/checklist/#checklist",
            "text": "This page maintains a list of upcoming tasks for the project, each task with a brief explanation, estimation of difficulty/time and connections with other tasks. Ideally this should be called  Roadmap  instead of  Checklist , but placing accurate milestones has proven to be hard.",
            "title": "Checklist"
        },
        {
            "location": "/checklist/#towards-a-todomvc-example",
            "text": "The tasks listed in this section are all necessary ones to achieve a more \"real-world\" browser example like TodoMVC. They are currently being worked on.",
            "title": "Towards a TodoMVC example"
        },
        {
            "location": "/checklist/#implement-foreign-export-javascript",
            "text": "We already can call JavaScript from Haskell via  foreign import javascript , for JavaScript to call into Haskell, we need to implement  foreign export javascript . The exported Haskell functions will be available as WebAssembly exported functions, callable in JavaScript land.  Requirements:   Implement  StablePtr , so that Haskell closures can be safely passed between Haskell/JavaScript boundary without being garbage collected. (done, see  stableptr  unit test)  Implement  RtsAPI , so that JavaScript code can create Haskell closures, trigger evaluation and inspect results. (done, see  rtsapi  unit test)  Add  StablePtr  to JSFFI basic types. (done, see  jsffi  unit test)  Implement  foreign export javascript  syntax, add necessary logic in  JSFFI / Resolve  (in progress)   Rough ETA: before Aug 20th.",
            "title": "Implement foreign export javascript"
        },
        {
            "location": "/checklist/#improve-haskelljavascript-marshalling",
            "text": "Most JavaScript types will appear as opaque  JSRef  in Haskell land, but for some types that appear very often (e.g. strings and arrays), we wish they can be marshalled from/to their Haskell equivalents (e.g. lists) smoothly. Without this, even implementing a  putStr  will be troublesome because we must either send individual  Char s to a TTY-device in JavaScript, or manually squeeze the string into a buffer in Haskell heap first.  Requirements:   Recognize  String / []  as special JSFFI basic types, add marshalling logic from/to JavaScript strings/arrays. (in progress)   When we support  aeson  in the future, it may even be possible to marshal between  Value s and JavaScript objects directly.",
            "title": "Improve Haskell/JavaScript marshalling"
        },
        {
            "location": "/checklist/#support-bytestring",
            "text": "bytestring  is a critical component in the Haskell ecosystem, we must support it regardless of what filthy hacks are deployed. At least non- Internal  modules need to be supported.  Requirements:   Add  bytestring  to boot libs.  Implement  Weak# , since  ByteString  needs finalizers  Implement WebAssembly shims in  Builtins  for required C functions.",
            "title": "Support bytestring"
        },
        {
            "location": "/checklist/#improve-wasmjs-generation",
            "text": "Currently, given a home module,  ahc-link  outputs a  .wasm  and a  .js  wrapper which runs in Node.js. We will need the whole thing to run in browser though.  Requirements:   Add logic in  ahc-link  to generate browser-friendly code  Make the test suite run via a headless browser, and properly retrieve results from the browser back to Haskell",
            "title": "Improve .wasm/.js generation"
        },
        {
            "location": "/checklist/#next-important-tasks",
            "text": "The following tasks are somewhat less important, but still necessary for end-user experience. They will be processed once the previous goal is accomplished.",
            "title": "Next important tasks"
        },
        {
            "location": "/checklist/#utilize-ghc-renamertypechecker-in-jsffi",
            "text": "Currently, the JSFFI thing works with parsed AST because it's less likely to mess up after rewriting. As a consequence:   JSRef  only works as a magic identifier. It's not in any actual Haskell module  No  newtypes  for JSFFI basic types, since we recognize types by  RdrName  only   We need to move JSFFI processing to the phase of renamer or typechecker.",
            "title": "Utilize GHC renamer/typechecker in JSFFI"
        },
        {
            "location": "/checklist/#support-javascript-promises-in-jsffi",
            "text": "The  foreign import javascript  syntax currently assumes the JavaScript computation is synchronous. We need to support asynchronous JavaScript computation, by adding a  foreign import javascript safe  construct, and assume the JavaScript computation returns a  Promise . Upon calling such a function, the scheduler saves thread state and gracefully halts the whole runtime. The runtime will be re-activated once the  Promise  is fulfilled.",
            "title": "Support JavaScript promises in JSFFI"
        },
        {
            "location": "/checklist/#add-growable-heapgarbage-collection-to-storage-manager",
            "text": "Currently, the heap size is fixed and can be specified by  ahc-link --heap-size . By defaulting a heap size of 1GB, we pretend memory is infinite and focus work on other issues, but this can come back to bite us at any time.  There are two steps in this tasks:   Implement growable heap. When GC is entered, we allocate fresh blocks and move the nursery/object pool to point to new blocks.  Implement garbage collection. Porting all GC routines is a huge amount of work and error-prone, so we implement a non-generational one in JavaScript.",
            "title": "Add growable heap/garbage collection to storage manager"
        },
        {
            "location": "/checklist/#solve-reference-leaking-in-jsffi",
            "text": "JSRef  is implemented much like  StablePtr : a mapping from handles to objects. Whenever a  JSRef  enters Haskell land, the underlying object is pointed to by a mapping, but currently there's no mechanism to free a  JSRef .  Some possible fixes:   Provide  freeJSRef  in Haskell land, works for any individual  JSRef  Provide  nukeJSRefs , can be called periodically to wipe all  JSRef s  Provide a region-based API, all  JSRef s are tied to a region. Regions themselves can be allocated and recycled. Optionally there can be a global region.",
            "title": "Solve reference leaking in JSFFI"
        },
        {
            "location": "/checklist/#improve-cabal-support",
            "text": "Currently,  Cabal  still thinks  ahc  is yet another  ghc  and feeds it with  ghc  command line arguments. We should teach it to regard  ahc  as a new Haskell compiler, and what to do for typical commands ( configure / build / install , etc).  After  Cabal  support is improved, we can:   Get away with current \"boot libs\" mechanism, instead rely on regular GHC package databases  Give users ability to build/use packages outside boot libs  Go on with improving  cabal-install , some day a plain  cabal build --asterius  may work",
            "title": "Improve Cabal support"
        },
        {
            "location": "/checklist/#improve-test-suite",
            "text": "The current test suites have poor coverage of Haskell features.",
            "title": "Improve test suite"
        },
        {
            "location": "/checklist/#archived-tasks",
            "text": "The following tasks have lower priority, either due to low impact to end-user experience or significant time involved. They are archived here and may be revisited at a later date, and we're still happy to discuss or review a pull request.",
            "title": "Archived tasks"
        },
        {
            "location": "/checklist/#implement-template-haskellghci",
            "text": "There are two possible ways to implement Template Haskell/GHCi:   Link with the native code produced when booting. For simple  Q  computations that doesn't involve  runIO  this should work fine, but it won't work when one calls a WebAssembly computation in  Q .  Implement the remote interpreter for WebAssembly, much like ghcjs. When Template Haskell/GHCi is involved, we fire up a Node.js/Headless Chrome process and do all the message passing. This is the ideal solution but takes a huge amount of work.",
            "title": "Implement Template Haskell/GHCi"
        },
        {
            "location": "/checklist/#improve-webassembly-edsl",
            "text": "We already have a monadic EDSL for constructing WebAssembly code. There are still minor flaws with current EDSL:   No notion of  struct s. We manually load/store via a base pointer and an offset.  Not type-safe. It's possible to mix-up  I32 / I64  stuff and it's not always possible for  binaryen  validator to catch the problem (especially when load/store is involved)  Global/static variables need a lot of boilerplate",
            "title": "Improve WebAssembly EDSL"
        },
        {
            "location": "/checklist/#switch-away-from-binaryen",
            "text": "binaryen  is a fantastic library for WebAssembly code generation and has powered  asterius  since the beginning. However, there are reasons to switch away and implement our own WebAssembly code generation library:   The relooper has been a constant source of trouble. We already implement our own relooper now.  There's no support for linking and symbol resolution, so we have to keep two sets of types for WebAssembly: one is our own for pre-linking modules, one is the final linked data to feed to  binaryen , but they overlap a lot.  binaryen  is conservative in features. We'd like to try experimental WebAssembly features (exception handling, multi-return, anyref, etc) in V8.",
            "title": "Switch away from binaryen"
        },
        {
            "location": "/checklist/#integrate-llvmclang-or-emscripten",
            "text": "It's a shame we can't compile simple  cbits  in Haskell packages and have to hand-write WebAssembly code instead.",
            "title": "Integrate LLVM/Clang or Emscripten"
        },
        {
            "location": "/checklist/#implement-try-asterius-website",
            "text": "To increase momentum for this project, it'd be nice to have a \"try asterius\" website, where people can send snippets of modules and download compiled code to run in their browsers.",
            "title": "Implement \"Try asterius\" website"
        },
        {
            "location": "/checklist/#add-macos-support",
            "text": "Currently we don't build GHC bindists for macOS and test it on CircleCI. For the sake of macOS Haskellers this should be implemented.",
            "title": "Add macOS support"
        },
        {
            "location": "/checklist/#add-nixbazel-support",
            "text": "It'd be nice to support building the project via Nix/Bazel.",
            "title": "Add Nix/Bazel support"
        },
        {
            "location": "/checklist/#support-integer-gmp",
            "text": "We currently use  integer-simple , but not all packages implement the flags to switch away from  integer-gmp .  It's worth mentioning that V8 already has experimental support for the BigInt proposal, so  Integer s should ideally be powered by  bigint s under the hood.",
            "title": "Support integer-gmp"
        },
        {
            "location": "/checklist/#support-tables-next-to-code",
            "text": "Of course, we know the WebAssembly standard separates data and code, so something like tables-next-to-code won't work; but come to think of it, at link time we already know the absolute addresses of \"code\", so we can cheat a little bit here..  If we support both  integer-gmp  and tables-next-to-code, we can stop requiring users to set up a custom GHC first, and can distribute  asterius  as a vanilla package.",
            "title": "Support tables-next-to-code"
        },
        {
            "location": "/wasm-in-hs/",
            "text": "Writing WebAssembly code in Haskell\n\n\nIn \nAsterius.Builtins\n, there are WebAssembly shims which serve as our runtime. We choose to write WebAssembly code in Haskell, using Haskell as our familiar meta-language.\n\n\nAs of now, there are two ways of writing WebAssembly code in Haskell. The first way is directly manipulating AST types as specified in \nAsterius.Types\n. Those types are pretty bare-metal and maps closely to binaryen IR. Simply write some code to generate an \nAsteriusFunction\n, and ensure the function and its symbol is present in the store when linking starts. It will eventually be bundled into output WebAssembly binary file.\n\n\nDirectly using \nAsterius.Types\n is not a pleasant experience, it's basically a DDoS on one's working memory, since the developer needs to keep a lot of things in mind: parameter/local ids, block/loop labels, etc. Also, the resulting Haskell code is pretty verbose, littered with syntactic noise (e.g. tons of list concats when constructing a block)\n\n\nWe now provide an EDSL in \nAsterius.EDSL\n to construct an \nAsteriusFunction\n. Its core type is \nEDSL a\n, and can be composed with a \nMonad\n or \nMonoid\n interface. Most builtin functions in \nAsterius.Builtins\n are already refactored to use this EDSL. Typical usages:\n\n\n\n\n\"Allocate\" a parameter/local. Use \nparam\n or \nlocal\n to obtain an immutable \nExpression\n which corresponds to the value of a new parameter/local. There are also mutable variants.\n\n\nAn opaque \nLVal\n type is provided to uniformly deal with local reads/assignments and memory loads/stores. Once an \nLVal\n is instantiated, it can be used to read an \nExpression\n in the pure world, or set an \nExpression\n in the \nEDSL\n monad.\n\n\nSeveral side-effecting instructions can simply be composed with the monadic/monoidal interface, without the need to explicitly construct an anonymous block.\n\n\nWhen we need named blocks/loops with branching instructions inside, use the \nblock\n/\nloop\n combinators which has the type \n(Label -> EDSL ()) -> EDSL ()\n. Inside the passed in continuation, we can use \nbreak'\n to perform branching. The \nLabel\n type is also opaque and cannot be inspected, the only thing we know is that it's scope-checked just like any ordinary Haskell value, so it's impossible to accidently branch to an \"inner\" label.\n\n\n\n\nThe EDSL only checks for scope safety, so we don't mess up different locals or jump to non-existent labels. Type-safety is not guaranteed (binaryen validator checks for it anyway). Underneath it's just a shallow embedded DSL implemented with a plain old state monad. Some people call it the \"remote monad design pattern\".",
            "title": "Writing WebAssembly code in Haskell"
        },
        {
            "location": "/wasm-in-hs/#writing-webassembly-code-in-haskell",
            "text": "In  Asterius.Builtins , there are WebAssembly shims which serve as our runtime. We choose to write WebAssembly code in Haskell, using Haskell as our familiar meta-language.  As of now, there are two ways of writing WebAssembly code in Haskell. The first way is directly manipulating AST types as specified in  Asterius.Types . Those types are pretty bare-metal and maps closely to binaryen IR. Simply write some code to generate an  AsteriusFunction , and ensure the function and its symbol is present in the store when linking starts. It will eventually be bundled into output WebAssembly binary file.  Directly using  Asterius.Types  is not a pleasant experience, it's basically a DDoS on one's working memory, since the developer needs to keep a lot of things in mind: parameter/local ids, block/loop labels, etc. Also, the resulting Haskell code is pretty verbose, littered with syntactic noise (e.g. tons of list concats when constructing a block)  We now provide an EDSL in  Asterius.EDSL  to construct an  AsteriusFunction . Its core type is  EDSL a , and can be composed with a  Monad  or  Monoid  interface. Most builtin functions in  Asterius.Builtins  are already refactored to use this EDSL. Typical usages:   \"Allocate\" a parameter/local. Use  param  or  local  to obtain an immutable  Expression  which corresponds to the value of a new parameter/local. There are also mutable variants.  An opaque  LVal  type is provided to uniformly deal with local reads/assignments and memory loads/stores. Once an  LVal  is instantiated, it can be used to read an  Expression  in the pure world, or set an  Expression  in the  EDSL  monad.  Several side-effecting instructions can simply be composed with the monadic/monoidal interface, without the need to explicitly construct an anonymous block.  When we need named blocks/loops with branching instructions inside, use the  block / loop  combinators which has the type  (Label -> EDSL ()) -> EDSL () . Inside the passed in continuation, we can use  break'  to perform branching. The  Label  type is also opaque and cannot be inspected, the only thing we know is that it's scope-checked just like any ordinary Haskell value, so it's impossible to accidently branch to an \"inner\" label.   The EDSL only checks for scope safety, so we don't mess up different locals or jump to non-existent labels. Type-safety is not guaranteed (binaryen validator checks for it anyway). Underneath it's just a shallow embedded DSL implemented with a plain old state monad. Some people call it the \"remote monad design pattern\".",
            "title": "Writing WebAssembly code in Haskell"
        },
        {
            "location": "/jsffi/",
            "text": "JavaScript FFI\n\n\nThere is a prototype implementation of \nforeign import javascript\n right now, check the \njsffi\n test suite for details. The syntax is like:\n\n\nforeign import javascript \"new Date()\" current_time :: IO JSRef\n\nforeign import javascript \"console.log(${1})\" js_print :: JSRef -> IO ()\n\n\n\n\nThe source text of \nforeign import javascript\n should be a valid JavaScript expression (but you can use something like \n${1}\n, \n${2}\n to refer to the function parameters). Supported types are:\n\n\n\n\nPtr\n\n\nFunPtr\n\n\nStablePtr\n\n\nInt\n\n\nWord\n\n\nChar\n\n\nFloat\n\n\nDouble\n\n\nJSRef\n\n\n\n\nJSRef\n is a magic type that doesn't actually appear in any module's source code. In the Haskell land, \nJSRef\n is first-class and opaque: you can pass it around, put it in a data structure, etc, but under the hood it's just a handle. The runtime maintains mappings from handles to real JavaScript objects.",
            "title": "JavaScript FFI"
        },
        {
            "location": "/jsffi/#javascript-ffi",
            "text": "There is a prototype implementation of  foreign import javascript  right now, check the  jsffi  test suite for details. The syntax is like:  foreign import javascript \"new Date()\" current_time :: IO JSRef\n\nforeign import javascript \"console.log(${1})\" js_print :: JSRef -> IO ()  The source text of  foreign import javascript  should be a valid JavaScript expression (but you can use something like  ${1} ,  ${2}  to refer to the function parameters). Supported types are:   Ptr  FunPtr  StablePtr  Int  Word  Char  Float  Double  JSRef   JSRef  is a magic type that doesn't actually appear in any module's source code. In the Haskell land,  JSRef  is first-class and opaque: you can pass it around, put it in a data structure, etc, but under the hood it's just a handle. The runtime maintains mappings from handles to real JavaScript objects.",
            "title": "JavaScript FFI"
        },
        {
            "location": "/debugging/",
            "text": "The runtime debugging feature\n\n\nThere is a runtime debugging mode which can be enabled by the \n--debug\n flag for \nahc-link\n. When enabled, the compiler inserts \"tracing\" instructions in the following places:\n\n\n\n\nThe start of a function/basic block\n\n\nSetLocal\n when the local type is \nI64\n\n\nMemory load/stores, when the value type is \nI64\n\n\n\n\nThe tracing messages are quite helpful in observing control flow transfers and memory operations. Remember to also use the \n--output-link-report\n flag to dump the linking report, which contains mapping from data/function symbols to addresses.\n\n\nThe runtime debugging mode also enables a \"memory trap\" which intercepts every memory load/store instruction and checks if the address is null pointer or other uninitialized regions of the linear memory. The program immediately aborts if an invalid address is encountered. (When debugging mode is switched off, program continues execution and the rest of control flow is all undefined behavior!)",
            "title": "The runtime debugging feature"
        },
        {
            "location": "/debugging/#the-runtime-debugging-feature",
            "text": "There is a runtime debugging mode which can be enabled by the  --debug  flag for  ahc-link . When enabled, the compiler inserts \"tracing\" instructions in the following places:   The start of a function/basic block  SetLocal  when the local type is  I64  Memory load/stores, when the value type is  I64   The tracing messages are quite helpful in observing control flow transfers and memory operations. Remember to also use the  --output-link-report  flag to dump the linking report, which contains mapping from data/function symbols to addresses.  The runtime debugging mode also enables a \"memory trap\" which intercepts every memory load/store instruction and checks if the address is null pointer or other uninitialized regions of the linear memory. The program immediately aborts if an invalid address is encountered. (When debugging mode is switched off, program continues execution and the rest of control flow is all undefined behavior!)",
            "title": "The runtime debugging feature"
        },
        {
            "location": "/architecture/",
            "text": "High-level architecture\n\n\nThe \nasterius\n project is hosted at \nGitHub\n. The monorepo contains several packages:\n\n\n\n\nasterius\n. This is the central package of the \nasterius\n compiler.\n\n\nbinaryen\n. It contains the latest source code of the C++ library \nbinaryen\n in tree, and provides complete raw bindings to its \nC API\n.\n\n\nghc-toolkit\n. It provides a framework for implementing Haskell-to-X compilers by retrieving \nghc\n's various types of in-memory intermediate representations. It also contains the latest source code of \nghc-prim\n/\ninteger-gmp\n/\ninteger-simple\n/\nbase\n in tree.\n\n\n\n\nThe \nasterius\n package provides an \nahc\n executable which is a drop-in replacement of \nghc\n to be used with \nSetup configure\n. \nahc\n redirects all arguments to the real \nghc\n most of the time, but when it's invoked with the \n--make\n major mode, it invokes \nghc\n with its frontend plugin. This is inspired by Edward Yang's \nHow to integrate GHC API programs with Cabal\n.\n\n\nBased on \nghc-toolkit\n, \nasterius\n implements a \nghc\n frontend plugin\n which translates \nCmm\n to \nbinaryen\n IR. The serialized \nbinaryen\n IR can then be loaded and linked to a WebAssembly binary (not implemented yet). The normal compilation pipeline which generates native machine code is not affected.\n\n\nAbout \"booting\"\n\n\nIn order for \nasterius\n to support non-trivial Haskell programs (that is, at least most things in \nPrelude\n), it needs to run the compilation process for \nbase\n and its dependent packages. This process is known as \"booting\".\n\n\nThe \nasterius\n package provides an \nahc-boot\n test suite which tests booting by compiling the wired-in packages provided by \nghc-toolkit\n and using \nahc\n to replace \nghc\n when configuring. This is inspired by Joachim Breitner's \nveggies\n.",
            "title": "Project architecture"
        },
        {
            "location": "/architecture/#high-level-architecture",
            "text": "The  asterius  project is hosted at  GitHub . The monorepo contains several packages:   asterius . This is the central package of the  asterius  compiler.  binaryen . It contains the latest source code of the C++ library  binaryen  in tree, and provides complete raw bindings to its  C API .  ghc-toolkit . It provides a framework for implementing Haskell-to-X compilers by retrieving  ghc 's various types of in-memory intermediate representations. It also contains the latest source code of  ghc-prim / integer-gmp / integer-simple / base  in tree.   The  asterius  package provides an  ahc  executable which is a drop-in replacement of  ghc  to be used with  Setup configure .  ahc  redirects all arguments to the real  ghc  most of the time, but when it's invoked with the  --make  major mode, it invokes  ghc  with its frontend plugin. This is inspired by Edward Yang's  How to integrate GHC API programs with Cabal .  Based on  ghc-toolkit ,  asterius  implements a  ghc  frontend plugin  which translates  Cmm  to  binaryen  IR. The serialized  binaryen  IR can then be loaded and linked to a WebAssembly binary (not implemented yet). The normal compilation pipeline which generates native machine code is not affected.",
            "title": "High-level architecture"
        },
        {
            "location": "/architecture/#about-booting",
            "text": "In order for  asterius  to support non-trivial Haskell programs (that is, at least most things in  Prelude ), it needs to run the compilation process for  base  and its dependent packages. This process is known as \"booting\".  The  asterius  package provides an  ahc-boot  test suite which tests booting by compiling the wired-in packages provided by  ghc-toolkit  and using  ahc  to replace  ghc  when configuring. This is inspired by Joachim Breitner's  veggies .",
            "title": "About \"booting\""
        },
        {
            "location": "/webassembly/",
            "text": "WebAssembly as a Haskell compilation target\n\n\nThere are a few issues to address when compiling Cmm to WebAssembly.\n\n\nImplementing Haskell Stack/Heap\n\n\nThe Haskell runtime maintains a TSO(Thread State Object) for each Haskell thread, and each TSO contains a separate stack for the STG machine. The WebAssembly platform has its own \"stack\" concept though; the execution of WebAssembly is based on a stack machine model, where instructions consume operands on the stack and push new values onto it.\n\n\nWe use the linear memory to simulate Haskell stack/heap. Popping/pushing the Haskell stack only involves loading/storing on the linear memory. Heap allocation only involves bumping the heap pointer. Running out of space will trigger a WebAssembly trap, instead of doing GC.\n\n\nAll discussions in the documentation use the term \"stack\" for the Haskell stack, unless explicitly stated otherwise.\n\n\nImplementing STG machine registers\n\n\nThe Haskell runtime makes use of \"virtual registers\" like Sp, Hp or R1 to implement the STG machine. The NCG(Native Code Generator) tries to map some of the virtual registers to real registers when generating assembly code. However, WebAssembly doesn't have language constructs that map to real registers, so we simply implement Cmm local registers as WebAssembly locals, and global registers as fields of \nStgRegTable\n.\n\n\nHandling control flow\n\n\nWebAssembly currently enforces structured control flow, which prohibits arbitrary branching. Also, explicit tail calls are missing.\n\n\nThe Cmm control flow mainly involves two forms of branching: in-function or cross-function. Each function consists of a map from \nhoopl\n labels to basic blocks and an entry label. Branching happens at the end of each basic block.\n\n\nIn-function branching is relatively easier to handle. \nbinaryen\n provides a \"relooper\" which can recover WebAssembly instructions with structured control flow from a control-flow graph. Note that we're using our own relooper though, see issue \n#22\n for relevant discussion.\n\n\nCross-function branching (\nCmmCall\n) is tricky. WebAssembly lacks explicit tail calls, and the relooper can't be easily used in this case since there's a computed goto, and potential targets include all Cmm blocks involved in linking. There are multiple possible ways to handle this situation:\n\n\n\n\nCollect all Cmm blocks into one function, additionally add a \"dispatcher\" block. All \nCmmCall\ns save the callee to a register and branch to the \"dispatcher\" block, and the \"dispatcher\" uses \nbr_table\n or a binary decision tree to branch to the entry block of callee.\n\n\nOne WebAssembly function for one \nCmmProc\n, and upon \nCmmCall\n the function returns the function id of callee. A mini-interpreter function at the top level repeatedly invoke the functions using \ncall_indirect\n. This approach is actually used by the unregisterised mode of \nghc\n.\n\n\n\n\nWe're using the latter approach: every \nCmmProc\n marshals to one WebAssembly function. This choice is tightly coupled with some other functionalities (e.g. debug mode) and it'll take quite some effort to switch away.\n\n\nHandling relocations\n\n\nWhen producing a WebAssembly binary, we need to map \nCLabel\ns to the precise linear memory locations for \nCmmStatics\n or the precise table ids for \nCmmProc\ns. They are unknown when compiling individual modules, so \nbinaryen\n is invoked only when linking, and during compiling we only convert \nCLabel\ns to some serializable representation.\n\n\nCurrently WebAssembly community has a \nproposal\n for linkable object format, and it's prototyped by \nlld\n. We'll probably turn to that format and use \nlld\n some day, but right now we'll simply stick to our own format for simplicity.\n\n\nThe word size story\n\n\nAlthough \nwasm64\n is scheduled, currently only \nwasm32\n is implemented. However, we are running 64-bit \nghc\n, and there are several places which need extra care:\n\n\n\n\nThe load/store instructions operate on 64-bit addresses, yet \nwasm32\n use \nuint32\n when indexing into the linear memory.\n\n\nThe \nCmmSwitch\n labels are 64-bit. \nCmmCondBranch\n also checks a 64-bit condition. \nbr_if\n/\nbr_table\n operates on \nuint32\n.\n\n\nOnly \ni32\n/\ni64\n is supported by \nwasm32\n value types, but in Cmm we also need arithmetic on 8-bit/16-bit integers.\n\n\n\n\nWe insert instructions for converting between 32/64-bits in the codegen. The \nbinaryen\n validator also helps checking bit lengths.\n\n\nAs for booleans: there's no native boolean type in either WebAssembly or Cmm. As a convention we use \nuint32\n.\n\n\nPages and addresses\n\n\nThe WebAssembly linear memory has a hard-coded page size of 64KB. There are several places which operate in units of pages rather than raw bytes:\n\n\n\n\nCurrentMemory\n/\nGrowMemory\n\n\nMemory\n component of a \nModule\n\n\n\n\nWhen performing final linking, we layout static data segments to the linear memory. We ensure the memory size is always divisable by \nMBLOCK_SIZE\n, so it's easy to allocate new mega blocks and calculate required page count.\n\n\nThe first 8 bytes of linear memory (from 0x0 to 0x7) are uninitialized. 0x0 is treated as null pointer, and loading/storing on null pointer or other uninitialized regions is prohibited. In debug mode the program immediately aborts.",
            "title": "WebAssembly as a Haskell compilation target"
        },
        {
            "location": "/webassembly/#webassembly-as-a-haskell-compilation-target",
            "text": "There are a few issues to address when compiling Cmm to WebAssembly.",
            "title": "WebAssembly as a Haskell compilation target"
        },
        {
            "location": "/webassembly/#implementing-haskell-stackheap",
            "text": "The Haskell runtime maintains a TSO(Thread State Object) for each Haskell thread, and each TSO contains a separate stack for the STG machine. The WebAssembly platform has its own \"stack\" concept though; the execution of WebAssembly is based on a stack machine model, where instructions consume operands on the stack and push new values onto it.  We use the linear memory to simulate Haskell stack/heap. Popping/pushing the Haskell stack only involves loading/storing on the linear memory. Heap allocation only involves bumping the heap pointer. Running out of space will trigger a WebAssembly trap, instead of doing GC.  All discussions in the documentation use the term \"stack\" for the Haskell stack, unless explicitly stated otherwise.",
            "title": "Implementing Haskell Stack/Heap"
        },
        {
            "location": "/webassembly/#implementing-stg-machine-registers",
            "text": "The Haskell runtime makes use of \"virtual registers\" like Sp, Hp or R1 to implement the STG machine. The NCG(Native Code Generator) tries to map some of the virtual registers to real registers when generating assembly code. However, WebAssembly doesn't have language constructs that map to real registers, so we simply implement Cmm local registers as WebAssembly locals, and global registers as fields of  StgRegTable .",
            "title": "Implementing STG machine registers"
        },
        {
            "location": "/webassembly/#handling-control-flow",
            "text": "WebAssembly currently enforces structured control flow, which prohibits arbitrary branching. Also, explicit tail calls are missing.  The Cmm control flow mainly involves two forms of branching: in-function or cross-function. Each function consists of a map from  hoopl  labels to basic blocks and an entry label. Branching happens at the end of each basic block.  In-function branching is relatively easier to handle.  binaryen  provides a \"relooper\" which can recover WebAssembly instructions with structured control flow from a control-flow graph. Note that we're using our own relooper though, see issue  #22  for relevant discussion.  Cross-function branching ( CmmCall ) is tricky. WebAssembly lacks explicit tail calls, and the relooper can't be easily used in this case since there's a computed goto, and potential targets include all Cmm blocks involved in linking. There are multiple possible ways to handle this situation:   Collect all Cmm blocks into one function, additionally add a \"dispatcher\" block. All  CmmCall s save the callee to a register and branch to the \"dispatcher\" block, and the \"dispatcher\" uses  br_table  or a binary decision tree to branch to the entry block of callee.  One WebAssembly function for one  CmmProc , and upon  CmmCall  the function returns the function id of callee. A mini-interpreter function at the top level repeatedly invoke the functions using  call_indirect . This approach is actually used by the unregisterised mode of  ghc .   We're using the latter approach: every  CmmProc  marshals to one WebAssembly function. This choice is tightly coupled with some other functionalities (e.g. debug mode) and it'll take quite some effort to switch away.",
            "title": "Handling control flow"
        },
        {
            "location": "/webassembly/#handling-relocations",
            "text": "When producing a WebAssembly binary, we need to map  CLabel s to the precise linear memory locations for  CmmStatics  or the precise table ids for  CmmProc s. They are unknown when compiling individual modules, so  binaryen  is invoked only when linking, and during compiling we only convert  CLabel s to some serializable representation.  Currently WebAssembly community has a  proposal  for linkable object format, and it's prototyped by  lld . We'll probably turn to that format and use  lld  some day, but right now we'll simply stick to our own format for simplicity.",
            "title": "Handling relocations"
        },
        {
            "location": "/webassembly/#the-word-size-story",
            "text": "Although  wasm64  is scheduled, currently only  wasm32  is implemented. However, we are running 64-bit  ghc , and there are several places which need extra care:   The load/store instructions operate on 64-bit addresses, yet  wasm32  use  uint32  when indexing into the linear memory.  The  CmmSwitch  labels are 64-bit.  CmmCondBranch  also checks a 64-bit condition.  br_if / br_table  operates on  uint32 .  Only  i32 / i64  is supported by  wasm32  value types, but in Cmm we also need arithmetic on 8-bit/16-bit integers.   We insert instructions for converting between 32/64-bits in the codegen. The  binaryen  validator also helps checking bit lengths.  As for booleans: there's no native boolean type in either WebAssembly or Cmm. As a convention we use  uint32 .",
            "title": "The word size story"
        },
        {
            "location": "/webassembly/#pages-and-addresses",
            "text": "The WebAssembly linear memory has a hard-coded page size of 64KB. There are several places which operate in units of pages rather than raw bytes:   CurrentMemory / GrowMemory  Memory  component of a  Module   When performing final linking, we layout static data segments to the linear memory. We ensure the memory size is always divisable by  MBLOCK_SIZE , so it's easy to allocate new mega blocks and calculate required page count.  The first 8 bytes of linear memory (from 0x0 to 0x7) are uninitialized. 0x0 is treated as null pointer, and loading/storing on null pointer or other uninitialized regions is prohibited. In debug mode the program immediately aborts.",
            "title": "Pages and addresses"
        },
        {
            "location": "/readings/",
            "text": "Reading list\n\n\nHere is a brief list of relevant readings about GHC internals and WebAssembly suited for newcomers.\n\n\n\n\nGHC documentation regarding the GHC API\n: a nice reading for anyone looking forward to using the GHC API.\n\n\nGHC commentary\n: a wiki containing lots of additional knowledge regarding GHC's implementation. Keep in mind some content is out-dated though. Some useful entries regarding this project:\n\n\nBuilding guide\n. A tl;dr for this section is our CI scripts.\n\n\nOverview of pipeline\n: we use the Hooks mechanism (specifically, \nrunPhaseHook\n) to replace the default pipeline with our own, to enable manipulation of in-memory IRs.\n\n\nHow STG works\n: a nice tutorial containing several examples of compiled examples, illustrating how the generated code works under the hood.\n\n\nThe Cmm types\n: it's outdated and the types don't exactly match the GHC codebase now, but the explanations still shed some light on how the current Cmm types work.\n\n\nThe runtime system\n: content regarding the runtime system.\n\n\n\n\n\n\nUnderstanding the Stack\n: A blog post explaining how generated code works at the assembly level. Also, its sequel \nUnderstanding the RealWorld\n\n\nThe WebAssembly spec\n: a useful reference regarding what's already present in WebAssembly.\n\n\nThe \nbinaryen\n C API\n: \nbinaryen\n handles WebAssembly code generation. There are a few differences regarding \nbinaryen\n AST and WebAssembly AST, the most notable ones:\n\n\nbinaryen\n uses a recursive \nBinaryenExpression\n which is side-effectful. The original WebAssembly standard instead uses a stack-based model and manipulates the operand stack with instructions.\n\n\nbinaryen\n contains a \"Relooper\" which can recover high-level structured control flow from a CFG. However the relooper doesn't handle jumping to unknown labels (aka computed goto), so we don't use it to handle tail calls.\n\n\n\n\n\n\n\n\nThe following entries are papers which consume much more time to read, but still quite useful for newcomers:\n\n\n\n\nMaking a fast curry: push/enter vs. eval/apply for higher-order languages\n: A thorough explanation of what is STG and how it is implemented (via two different groups of rewrite rules, also with real benchmarks)\n\n\nThe STG runtime system (revised)\n: Includes some details on the runtime system and worth a read. It's a myth why it's not merged with the commentary though. Install a TeX distribution like TeX Live or use a service like Overleaf to compile the \n.tex\n file to \n.pdf\n before reading.\n\n\nThe GHC storage manager\n: Similar to above.\n\n\nBringing the Web up to Speed with WebAssembly\n: The PLDI'17 paper about WebAssembly. Contains overview of WebAssembly design rationales and rules of small-step operational semantics.\n\n\n\n\nFinally, the GHC codebase itself is also a must-read, but since it's huge we only need to check relevant parts when unsure about its behavior. Tips on reading GHC code:\n\n\n\n\nThere are a lot of insightful and up-to-date comments which all begin with \"Notes on xxx\". It's a pity the notes are neither collected into the sphinx-generated documentation or into the haddock docs of GHC API.\n\n\nWhen writing \nbuild.mk\n for compiling GHC, add \nHADDOCK_DOCS = YES\n to ensure building haddock docs of GHC API, and \nEXTRA_HADDOCK_OPTS += --quickjump --hyperlinked-source\n to enable symbol hyperlinks in the source pages. This will save you tons of time from \ngrep\ning the ghc codebase.\n\n\ngrep\ning is still unavoidable in some cases, since there's a lot of CPP involved and they aren't well handled by haddock.",
            "title": "Reading list"
        },
        {
            "location": "/readings/#reading-list",
            "text": "Here is a brief list of relevant readings about GHC internals and WebAssembly suited for newcomers.   GHC documentation regarding the GHC API : a nice reading for anyone looking forward to using the GHC API.  GHC commentary : a wiki containing lots of additional knowledge regarding GHC's implementation. Keep in mind some content is out-dated though. Some useful entries regarding this project:  Building guide . A tl;dr for this section is our CI scripts.  Overview of pipeline : we use the Hooks mechanism (specifically,  runPhaseHook ) to replace the default pipeline with our own, to enable manipulation of in-memory IRs.  How STG works : a nice tutorial containing several examples of compiled examples, illustrating how the generated code works under the hood.  The Cmm types : it's outdated and the types don't exactly match the GHC codebase now, but the explanations still shed some light on how the current Cmm types work.  The runtime system : content regarding the runtime system.    Understanding the Stack : A blog post explaining how generated code works at the assembly level. Also, its sequel  Understanding the RealWorld  The WebAssembly spec : a useful reference regarding what's already present in WebAssembly.  The  binaryen  C API :  binaryen  handles WebAssembly code generation. There are a few differences regarding  binaryen  AST and WebAssembly AST, the most notable ones:  binaryen  uses a recursive  BinaryenExpression  which is side-effectful. The original WebAssembly standard instead uses a stack-based model and manipulates the operand stack with instructions.  binaryen  contains a \"Relooper\" which can recover high-level structured control flow from a CFG. However the relooper doesn't handle jumping to unknown labels (aka computed goto), so we don't use it to handle tail calls.     The following entries are papers which consume much more time to read, but still quite useful for newcomers:   Making a fast curry: push/enter vs. eval/apply for higher-order languages : A thorough explanation of what is STG and how it is implemented (via two different groups of rewrite rules, also with real benchmarks)  The STG runtime system (revised) : Includes some details on the runtime system and worth a read. It's a myth why it's not merged with the commentary though. Install a TeX distribution like TeX Live or use a service like Overleaf to compile the  .tex  file to  .pdf  before reading.  The GHC storage manager : Similar to above.  Bringing the Web up to Speed with WebAssembly : The PLDI'17 paper about WebAssembly. Contains overview of WebAssembly design rationales and rules of small-step operational semantics.   Finally, the GHC codebase itself is also a must-read, but since it's huge we only need to check relevant parts when unsure about its behavior. Tips on reading GHC code:   There are a lot of insightful and up-to-date comments which all begin with \"Notes on xxx\". It's a pity the notes are neither collected into the sphinx-generated documentation or into the haddock docs of GHC API.  When writing  build.mk  for compiling GHC, add  HADDOCK_DOCS = YES  to ensure building haddock docs of GHC API, and  EXTRA_HADDOCK_OPTS += --quickjump --hyperlinked-source  to enable symbol hyperlinks in the source pages. This will save you tons of time from  grep ing the ghc codebase.  grep ing is still unavoidable in some cases, since there's a lot of CPP involved and they aren't well handled by haddock.",
            "title": "Reading list"
        }
    ]
}